To handle authentication for Gmail and Slack in your FastAPI AI agent using Composio, you will primarily use **OAuth 2.0 flows managed by Composio**. The key steps involve:
1.  **Initializing the Composio Python SDK** with your API key.
2.  **Authorizing user access** for Gmail and Slack separately using `composio.toolkits.authorize(user_id, toolkit="gmail/slack")`. This provides a `redirect_url` for user consent.
3.  **Waiting for connection confirmation** with `wait_for_connection()` after the user grants permission.
4.  **Fetching authorized tools** using `composio.tools.get(user_id, toolkits=["GMAIL", "SLACK"])` to get a `tools` object.
5.  **Passing this `tools` object to your AI model** (e.g., OpenAI) so it can decide when to use these tools.
6.  **Handling tool API calls** generated by the AI model using `composio.provider.handle_tool_calls(user_id, response)` to execute actions like reading Gmail or posting to Slack.

# Handling Authentication for Gmail and Slack in a FastAPI AI Agent using Composio

## 1. Core Challenge: Authenticating AI Agent with Gmail and Slack
The primary challenge revolves around enabling a web-based AI agent to securely authenticate with both Gmail and Slack services. This authentication is a prerequisite for the AI agent to perform actions such as reading user emails from Gmail and subsequently posting this information to Slack, based on user queries. The current development phase has successfully addressed tool discovery, meaning the AI agent can identify *what* needs to be done (e.g., read Gmail, post to Slack). However, the crucial step of *how* to authenticate with these external services before executing these tasks remains unresolved. The backend is built using FastAPI, a modern Python web framework, which will be instrumental in implementing the necessary OAuth 2.0 flows or other authentication mechanisms. The complexity lies in managing the distinct OAuth 2.0 protocols and credential management for both Google and Slack APIs, ensuring secure token handling, and integrating this seamlessly into the AI agent's workflow. This involves not just obtaining initial access tokens but also managing their lifecycle, including refreshing expired tokens, to maintain persistent and secure access to user data across these platforms.

### 1.1 User Query: "Read my recent Gmail and post it on Slack"
The AI agent is designed to process natural language user queries, such as **"read my recent Gmail and post it on Slack."** This type of query necessitates a multi-step operation involving two distinct third-party services: Gmail for data retrieval and Slack for data dissemination. To fulfill such a request, the AI agent must first understand the user's intent, then, crucially, establish authenticated connections to both the user's Gmail account and their specified Slack workspace or channel. The authentication process for each service will require the user's explicit consent to grant the AI agent the necessary permissions (scopes) to access their data and perform actions on their behalf. For Gmail, this would involve scopes like `https://www.googleapis.com/auth/gmail.readonly` or broader scopes if modifications are also intended. For Slack, scopes like `chat:write` (to post messages) and potentially `users:read` (to identify users or channels) would be required. The successful execution of this user query hinges on a robust and secure authentication mechanism that can handle these distinct OAuth 2.0 flows and manage the acquired credentials effectively within the FastAPI backend.

### 1.2 Current State: Tool discovery complete, authentication pending
The development of the AI agent has progressed to a stage where **"tool discovery" is complete**. This implies that the system can parse a user's query, identify the necessary actions (e.g., "read Gmail," "post to Slack"), and understand which external APIs or services are required to fulfill these actions. For instance, the agent recognizes that accessing Gmail involves using the Gmail API and that interacting with Slack requires the Slack API. However, the subsequent and critical step of **authenticating with these services is still pending**. This means that while the agent knows *what* tools to use, it cannot yet *use* them because it lacks the authorized access. The current roadblock is, therefore, the implementation of the authentication protocolsâ€”specifically OAuth 2.0 for both Gmail and Slackâ€”to obtain the access tokens that will allow the AI agent to make legitimate API calls. This involves setting up the OAuth 2.0 client credentials (client ID and client secret) for both Google Cloud Platform and Slack App, defining appropriate redirect URIs in the FastAPI backend, and implementing the necessary routes to handle the authorization code flow, token exchange, and token storage securely.

### 1.3 Backend: FastAPI
The backend of the web-based AI agent is built using **FastAPI**, a high-performance Python web framework. FastAPI is well-suited for this task due to its modern features, including native support for asynchronous programming (using `async` and `await`), automatic data validation and serialization via Pydantic models, and automatic generation of OpenAPI (Swagger) documentation. For implementing OAuth 2.0 authentication flows with Gmail and Slack, FastAPI provides the necessary tools and flexibility. This includes handling HTTP requests and responses, managing query parameters and request bodies, and interacting with external OAuth 2.0 providers. The backend will need to define specific API routes, such as `/auth/gmail/login` to initiate the Gmail OAuth flow, `/auth/gmail/callback` to handle the authorization response from Google, and similar routes for Slack. FastAPI's dependency injection system can be leveraged to manage application state, such as OAuth client configurations and session management for storing user-specific tokens. The choice of FastAPI also implies that Python libraries for OAuth (like `authlib` or `requests-oauthlib`) and for interacting with the Gmail and Slack APIs (like `google-api-python-client` and `slack_sdk`) will be utilized, or in this case, these complexities will be managed by Composio. The backend's responsibility will extend to securely storing and managing the obtained access tokens and refresh tokens, likely in a database associated with the user's session or account within the AI agent application, although Composio will handle much of this token management.

## 2. Proposed Solution: Leveraging Composio for OAuth Management
To address the challenge of authenticating the AI agent with Gmail and Slack, the proposed solution is to **leverage Composio for OAuth management**. Composio acts as an intermediary layer that simplifies the complex OAuth 2.0 flows and provides tools for easy integration and execution of actions on these third-party services. By using Composio, the development effort required to implement and maintain separate OAuth handshake mechanisms for Gmail, Slack, and potentially other future integrations is significantly reduced. Composio offers a unified interface and SDKs (Python and TypeScript) that abstract away the intricacies of OAuth, allowing developers to focus on the core functionality of the AI agent. This approach not only streamlines development but also enhances security by centralizing the management of credentials and access tokens.

### 2.1 Composio's Role: Simplifying OAuth flows and tool execution
**Composio plays a pivotal role in simplifying the complex OAuth 2.0 authentication flows** required for integrating third-party applications like Gmail and Slack into an AI agent . Instead of developers needing to implement and manage these OAuth protocols individually for each service, Composio provides a unified interface and SDK that abstracts these complexities . The core function of Composio, in this context, is to manage the end-to-end process of authorizing user access to these tools and subsequently handling the execution of API calls made by the AI agent to these services. This includes generating the necessary authorization URLs, handling redirects, managing access and refresh tokens, and providing a simplified way to invoke actions on the connected services. The Composio SDK, particularly its Python version, offers methods like `toolkits.authorize()` and `provider.handle_tool_calls()` which encapsulate the intricate details of OAuth and API interactions . This allows developers to focus on the core logic of their AI agent rather than the plumbing of API integrations and authentication mechanisms. The system is designed to support a wide array of tools, with documentation indicating support for **over 100+ tools and integrations** across various industry verticals , and even up to **3000+ tools** in other references , including popular services like GitHub, Notion, Linear, and Hubspot, in addition to Gmail and Slack . Composio's architecture is built around the concept of **"authenticated tool calling,"** which forms the foundation for connecting AI agents to real-world actions securely and efficiently .

### 2.2 Key Benefit: Automatic handling of OAuth for connected applications
The primary benefit of using Composio for integrating Gmail and Slack into an AI agent is its **ability to automatically handle the OAuth 2.0 flows and the execution of tool-specific API calls** . This automation significantly reduces the development effort and complexity associated with securing user consent, obtaining and refreshing access tokens, and managing API requests and responses. When a user initiates an action that requires access to, for example, their Gmail account, Composio's SDK facilitates a process where the user is redirected to Google's OAuth 2.0 consent screen. Once consent is granted, Composio manages the retrieval and storage of the access token, associating it with the specified `user_id`. Subsequently, when the AI agent needs to perform an action like reading an email, the SDK provides the necessary mechanisms to include this authorization context in the API call to Gmail. The documentation explicitly states, **"All OAuth flows and tool execution were automatically handled by Composio"** . This managed authentication extends to various protocols, including OAuth, API Keys, and Basic JWT, providing flexibility depending on the service being integrated . This abstraction layer is crucial for building robust and secure AI agents that can interact with multiple external services without the developer needing to become an expert in each service's specific authentication and API nuances. Composio's infrastructure is also built to **manage token refresh cycles transparently**, ensuring persistent connections .

## 3. Implementation Steps with Composio Python SDK
The Composio Python SDK provides a structured approach to handle the authentication and tool integration for applications like Gmail and Slack within an AI agent. The process involves initializing the SDK, authorizing user access for each required toolkit, fetching the authorized tools, and then integrating these tools with the AI agent. Finally, the agent's tool calls are handled by Composio, which manages the underlying API interactions. This systematic workflow ensures that the AI agent can securely and reliably interact with external services on behalf of the user. The SDK abstracts much of the OAuth complexity, allowing developers to focus on the core logic of their AI agent. The following subsections detail each step of this implementation, drawing from the Composio Quickstart documentation  and related examples.

### 3.1 SDK Initialization
Before any interactions with Composio's services, such as authorizing tools or fetching tool configurations, the Composio Python SDK must be properly initialized within the FastAPI backend. This initialization step is crucial as it establishes the connection between the application and Composio's platform, authenticates the application using an API key, and prepares the SDK for subsequent operations. The API key, typically stored as an environment variable, grants the application access to Composio's functionalities, including managing OAuth flows and executing tool actions. Proper initialization ensures that all subsequent calls to the Composio SDK are authenticated and authorized, forming the foundation for a secure and functional integration.

#### 3.1.1 Installation of Composio Python SDK
To begin integrating Composio into a Python-based project, such as a FastAPI backend, the first technical step is the **installation of the Composio Python SDK package**. This is typically achieved using a package manager like pip. The Composio Quickstart documentation  specifies the command `pip install composio==1.0.0rc9` for installing a specific release candidate version of the SDK. While newer stable versions might be available, this command indicates the version current at the time of the documentation's update. It is advisable to check the official Composio documentation or PyPI (Python Package Index) for the latest stable version to ensure compatibility and access to the most recent features and bug fixes. The installation process makes the Composio library's modules and classes available for import within the Python application, enabling developers to write code that interacts with Composio's services. This step is a prerequisite for initializing the SDK client and utilizing its methods for OAuth management and tool execution. The requirement for **Python 3.8+** is also explicitly stated as a prerequisite .

#### 3.1.2 Setting up Composio API Key
After installing the Composio Python SDK, the next critical step for its initialization is **providing an API key**. This key authenticates the application's requests to the Composio platform. The Composio Quickstart documentation  advises obtaining this API key from the Composio developer dashboard. For security best practices, this API key should not be hardcoded directly into the application's source code. Instead, it should be **stored as an environment variable**. The documentation suggests setting an environment variable named `COMPOSIO_API_KEY` with the value of the obtained key, for example, using the command `export COMPOSIO_API_KEY=your_api_key` in a Unix-like shell. In a production FastAPI application, this would typically involve setting the environment variable in the deployment environment (e.g., Docker, Kubernetes, or a serverless platform) or using a `.env` file that is loaded by the application at startup, ensuring that the API key is accessible to the SDK without being exposed in version control systems. The Composio client can then be initialized without explicitly passing the API key in the code if it's correctly set in the environment, as shown in the example `composio = Composio()` . Alternatively, the API key can be passed directly during client instantiation, like `Composio(api_key="your-api-key")`, though using environment variables is generally preferred for better security and configurability.

### 3.2 Authorizing Gmail Access
Once the Composio SDK is initialized, the next step in enabling an AI agent to interact with a user's Gmail account is to facilitate the OAuth 2.0 authorization flow. Composio simplifies this process by providing a method to initiate the authorization request and obtain a URL that the user must visit to grant permissions. This step is crucial for obtaining the necessary access tokens (managed by Composio) that allow the AI agent to perform actions on the user's behalf, such as reading emails. The process involves specifying the user and the desired toolkit (Gmail) to Composio, which then handles the intricacies of the OAuth protocol with Google's servers. This abstraction allows developers to integrate Gmail functionality without needing to implement the entire OAuth 2.0 flow from scratch, significantly reducing development time and complexity.

#### 3.2.1 Using `composio.toolkits.authorize(user_id, toolkit="gmail")`
To initiate the OAuth 2.0 authorization process for Gmail, the Composio Python SDK provides the **`authorize()` method within its `toolkits` module**. This method requires at least two key pieces of information: a `user_id` and the `toolkit` name. The `user_id` is a unique identifier for the user within the application's context. This identifier is crucial for Composio to associate the granted permissions and subsequent access tokens with the correct user, ensuring that the AI agent acts only on behalf of authenticated and authorized users. The `toolkit` parameter specifies the application for which authorization is being sought; in this case, it is **`"gmail"`**. The Composio Quickstart documentation  provides a clear example: `connection_request = composio.toolkits.authorize(user_id=user_id, toolkit="gmail")`. This call to `authorize()` returns a `connection_request` object, which contains essential information for continuing the OAuth flow, most notably the URL to which the user needs to be redirected to grant access. This method abstracts the initial steps of the OAuth 2.0 dance, such as generating a state token and constructing the authorization URL with the correct scopes and client ID.

#### 3.2.2 Obtaining and presenting the `redirect_url` to the user
After successfully calling `composio.toolkits.authorize(user_id, toolkit="gmail")`, the returned `connection_request` object contains a critical attribute: **`redirect_url`** . This URL is the gateway for the user to grant permissions to the application to access their Gmail account. The FastAPI backend must retrieve this URL and present it to the user, typically by redirecting the user's browser to this address or by providing the URL as a clickable link within the web application's UI. For example, the Composio Quickstart documentation  demonstrates printing the URL: `print(f"ðŸ”— Visit the URL to authorize:\nðŸ‘‰ {connection_request.redirect_url}")`. In a web-based AI agent, this would involve a more integrated user experience, such as rendering a page with a button that links to this `redirect_url` or initiating a server-side redirect. When the user visits this URL, they will be taken to Google's OAuth 2.0 consent screen, where they will be asked to log in (if not already) and then review the permissions the application is requesting. If the user approves, Google will redirect the user back to a pre-configured callback URL (managed by Composio), along with an authorization code. Composio then handles the exchange of this code for an access token and a refresh token, storing these securely associated with the provided `user_id`.

#### 3.2.3 Waiting for connection confirmation with `wait_for_connection()`
Once the user has been redirected to the `redirect_url` and has completed the authorization steps on Google's consent screen (either granting or denying access), the application needs a mechanism to determine the outcome before proceeding. The Composio Python SDK provides the **`wait_for_connection()` method on the `connection_request` object** for this purpose . This method is typically called after presenting the `redirect_url` to the user. It will block the execution of the subsequent code (or await, in an asynchronous context) until Composio has received the OAuth callback from Google and processed the authorization result. The Composio Quickstart documentation  shows this as `connection_request.wait_for_connection()`. During this period, Composio is effectively waiting for the user to complete the authorization flow in their browser. Once the user completes the action (granting or denying permissions), Composio's backend receives the authorization code, exchanges it for tokens, and updates the connection status. The `wait_for_connection()` call will then resolve, allowing the application to continue. If the authorization was successful, the connection to Gmail for that `user_id` is considered active, and the application can then proceed to fetch the tools for Gmail. If the authorization failed or was denied by the user, this method might raise an exception or return a status indicating the failure, which the application should handle gracefully.

### 3.3 Authorizing Slack Access
Similar to authorizing Gmail, enabling an AI agent to interact with a user's Slack workspace requires going through an OAuth 2.0 authorization flow, which Composio also simplifies. The process involves using the Composio SDK to initiate the authorization for the Slack toolkit. This will provide a URL for the user to grant the necessary permissions to the application to perform actions like posting messages or reading channel information. The `user_id` is again used to associate the Slack credentials with the specific user in the application. By leveraging Composio's `authorize()` method for Slack, developers can avoid the complexities of directly implementing Slack's OAuth 2.0 protocol, which involves registering an app with Slack, managing client secrets, and handling redirects and token exchanges. This streamlined approach allows for quicker integration of Slack functionalities into the AI agent.

#### 3.3.1 Using `composio.toolkits.authorize(user_id, toolkit="slack")`
To initiate the OAuth 2.0 authorization process for Slack, the same `authorize()` method from the Composio Python SDK's `toolkits` module is used, but with the `toolkit` parameter set to **`"slack"`**. The `user_id` parameter remains essential for associating the Slack permissions with the specific user in the application. The GitHub repository `composio-crewai-sample`  provides indirect confirmation of this pattern through its CLI setup instructions, which include `poetry run composio add slack`. This CLI command, when translated to SDK usage, aligns with the `authorize()` method for the Slack toolkit. Therefore, the Python code to initiate Slack authorization would be `connection_request = composio.toolkits.authorize(user_id=user_id, toolkit="slack")`. This call will trigger Composio to prepare an OAuth 2.0 authorization request for Slack, tailored with the necessary scopes and client information. The returned `connection_request` object will contain the `redirect_url` specific to Slack's authorization endpoint, which the user needs to visit. This consistent API pattern across different toolkits (Gmail, Slack, etc.) simplifies the developer experience when integrating multiple external services.

#### 3.3.2 Obtaining and presenting the Slack `redirect_url` to the user
Following the call to `composio.toolkits.authorize(user_id, toolkit="slack")`, the `connection_request` object returned will contain a **`redirect_url` attribute**, similar to the Gmail authorization flow. This URL is specific to Slack's OAuth 2.0 authorization endpoint. The FastAPI backend must extract this URL and ensure the user is directed to it. This could be achieved by returning the URL in an API response for the frontend to handle, by performing a server-side redirect, or by rendering a page with a link to this URL. For example, the code would be `print(f"ðŸ”— Visit the URL to authorize Slack:\nðŸ‘‰ {connection_request.redirect_url}")`, analogous to the Gmail example . When the user navigates to this URL, they will be prompted by Slack to log in (if necessary) and then to review and approve the permissions requested by the application. These permissions (scopes) are defined when the Composio integration for Slack is configured. Upon user approval, Slack will redirect back to a callback URL managed by Composio, including an authorization code. Composio then handles this code to obtain the necessary access tokens for interacting with the user's Slack workspace, securely linking these tokens to the provided `user_id`.

#### 3.3.3 Waiting for connection confirmation
After the user is presented with the Slack `redirect_url` and navigates to it to approve or deny the permissions, the backend needs to wait for this process to complete. Similar to the Gmail flow, the `connection_request` object obtained from `composio.toolkits.authorize(user_id, toolkit="slack")` will have a **`wait_for_connection()` method**. This method should be called to pause execution until Composio has received and processed the OAuth 2.0 callback from Slack. The call would be `connection_request.wait_for_connection()`. During this wait, Composio is expecting to receive the authorization code from Slack via its pre-configured callback URL. Once received, Composio will exchange this code for an access token (and potentially a refresh token) which it will store and manage. When `wait_for_connection()` completes, it signifies that the authorization process for Slack has concluded. If successful, the AI agent will then be able to use the Slack tools on behalf of that `user_id`. If the user denied the request or an error occurred, the method might indicate this through an exception or a specific return value, which the application should handle appropriately, perhaps by informing the user that Slack integration could not be completed.

### 3.4 Fetching Authorized Tools
Once the user has successfully authorized access to both Gmail and Slack (or any other required applications), the next step is to retrieve the actual tool configurations that the AI agent will use to interact with these services. Composio provides a method to fetch these "tools," which are essentially structured definitions (often in a format like OpenAI's function calling schema) that describe the available actions and their parameters for the authorized integrations. These tool definitions are what the AI model (e.g., GPT) will use to understand how to make API calls. The `user_id` is crucial here to ensure that only the tools for which that specific user has granted access are returned. This step bridges the gap between user consent and the AI agent's operational capabilities, providing it with the necessary "hands" to perform tasks.

#### 3.4.1 Using `composio.tools.get(user_id, toolkits=["GMAIL", "SLACK"])`
After successful authorization for Gmail and Slack, the Composio Python SDK allows the application to fetch the specific tool configurations using the **`composio.tools.get()` method**. This method requires the `user_id` to ensure that only tools authorized by that particular user are retrieved. Additionally, it accepts a `toolkits` parameter, which is a list of strings specifying the integrations for which tools are needed. Based on the Gmail example from the Composio Quickstart documentation , `tools = composio.tools.get(user_id=user_id, toolkits=["GMAIL"])`, and extending this to include Slack, the call would be **`tools = composio.tools.get(user_id=user_id, toolkits=["GMAIL", "SLACK"])`**. This instructs Composio to return the tool definitions for both Gmail and Slack that the specified `user_id` has access to. These tool definitions are typically structured in a way that is compatible with common LLM frameworks (like OpenAI's tool/function calling format), describing the available actions (e.g., "read_email", "send_slack_message"), their parameters, and other metadata. This consolidated list of tools is then ready to be passed to the AI agent.

#### 3.4.2 Obtaining the `tools` object for AI agent integration
The `composio.tools.get()` method, when called with the appropriate `user_id` and a list of authorized `toolkits` (e.g., `["GMAIL", "SLACK"]`), returns a **`tools` object** . This object is a collection of tool definitions, formatted in a way that AI models, particularly those supporting function or tool calling like OpenAI's `gpt-4o`, can understand and utilize. Each tool definition within this collection describes a specific action that can be performed on the integrated service (e.g., "list_emails" for Gmail, "post_message" for Slack). It includes details such as the name of the tool, a description of its purpose (which helps the LLM decide when to use it), and the parameters it accepts, including their types and descriptions. This `tools` object is a critical piece for the AI agent. It's not the executable code itself, but rather a schema that enables the LLM to reason about which tools to invoke and with what arguments based on the user's query. Once this `tools` object is obtained, it is passed to the LLM framework as part of the chat completion request, effectively arming the AI with the knowledge of what actions it can take.

### 3.5 Integrating with the AI Agent
With the `tools` object successfully retrieved from Composio, the next phase involves integrating these capabilities into the AI agent's decision-making and execution loop. This typically means providing the tool definitions to the Large Language Model (LLM) that powers the agent. Modern LLMs, such as OpenAI's GPT series, can be informed about available tools and can then decide, based on the user's input, whether and how to use these tools. The LLM doesn't execute the tools directly but rather outputs a structured request indicating a tool call, which the application backend then processes. This integration allows the AI agent to move beyond simple text generation to performing actions in the real world, such as reading emails or posting messages, by leveraging the authorized Gmail and Slack functionalities.

#### 3.5.1 Passing the `tools` object to the AI model (e.g., OpenAI)
Once the `tools` object, containing the definitions for Gmail and Slack actions, has been fetched from Composio using `composio.tools.get()`, this object needs to be passed to the AI model. If using the OpenAI Python SDK with a model like `gpt-4o` that supports tool calls, the `tools` object is included as a parameter in the chat completion request. The Composio Quickstart documentation  demonstrates this with **`openai.chat.completions.create(model="gpt-4o", messages=[...], tools=tools)`**. Here, `tools=tools` is the crucial part. The `tools` variable in this context is the one obtained from `composio.tools.get()`. By providing these tool definitions, the LLM becomes aware of the external capabilities available to it. When the LLM processes a user query like "read my recent Gmail and post it on Slack," it can analyze this query in the context of the provided `tools` and determine if any of the tools are relevant to fulfilling the request. If so, the LLM will generate a response that includes a specification for one or more tool calls, detailing which tool to use and what arguments to pass, rather than generating a direct text reply to the user. This mechanism allows the LLM to act as a planner and orchestrator of these external tools.

#### 3.5.2 Agent generates responses potentially involving tool API calls
After the AI model (e.g., an OpenAI LLM) has been provided with the `tools` object, its behavior changes when processing user queries. Instead of solely generating a textual response, the LLM will now analyze the query to determine if any of the registered tools can fulfill the user's request. If the LLM deems a tool necessary, its response will include a **structured `tool_calls` object** (or a similar construct, depending on the LLM provider). This object specifies which tool to invoke (e.g., `gmail.read_emails` or `slack.post_message`) and the arguments to pass to that tool (e.g., `{"max_results": 5}` for reading emails, or `{"channel": "general", "text": "Hello from AI!"}` for posting to Slack). The LLM itself does not execute these API calls; it merely outputs the intention to call a tool. The application's backend (the FastAPI server in this case) is responsible for intercepting this LLM response, parsing the `tool_calls` section, and then actually executing the requested actions. This is where Composio's `handle_tool_calls()` method comes into play, as it takes this LLM-generated tool call request and manages its execution against the real-world APIs of Gmail and Slack, using the user's previously authorized credentials.

### 3.6 Handling Tool API Calls
When the AI agent, powered by an LLM, determines that an external tool needs to be invoked to fulfill a user's request, it generates a structured tool call request. The backend application must then intercept this request and facilitate the actual execution of the API call to the respective service (e.g., Gmail or Slack). Composio provides a mechanism to handle these tool calls, abstracting away the details of making HTTP requests, managing authentication headers, and processing API responses. This ensures that the AI agent can reliably interact with external services using the credentials previously authorized by the user. The `user_id` is again important here to ensure that actions are performed on behalf of the correct user and with their specific permissions.

#### 3.6.1 Using `composio.provider.handle_tool_calls(user_id, response)`
When the AI model (e.g., from OpenAI) returns a response that includes a `tool_calls` section, indicating that one or more tools should be invoked, the Composio Python SDK offers the **`composio.provider.handle_tool_calls()` method** to manage the execution of these calls. This method takes two primary arguments: the `user_id` and the LLM's `response` object (which contains the `tool_calls`). The Composio Quickstart documentation  shows its usage as **`result = composio.provider.handle_tool_calls(user_id=user_id, response=completion)`**. The `user_id` ensures that Composio uses the correct set of credentials (access tokens) that were previously authorized by that specific user for the relevant tools (Gmail, Slack). Composio then iterates through the `tool_calls` in the LLM's response, maps each tool call to the corresponding API endpoint of the actual service (e.g., Gmail API's `users.messages.list` or Slack API's `chat.postMessage`), constructs the appropriate HTTP request with the necessary authentication headers and parameters (as specified by the LLM), and executes the call. This centralized handling simplifies the backend logic significantly, as the application doesn't need to implement separate clients for each integrated service.

#### 3.6.2 Executing actions like reading Gmail or posting to Slack
The `composio.provider.handle_tool_calls(user_id, response)` method is responsible for the **actual execution of the actions requested by the AI agent**. For a user query like "read my recent Gmail and post it on Slack," the LLM might first generate a tool call for `gmail.read_emails` (or a similar action defined in the Gmail tools). Composio's `handle_tool_calls()` method would execute this by making an authenticated request to the Gmail API, fetching the recent emails for the user identified by `user_id`. The results of this operation would be captured. Subsequently, if the LLM's plan involves posting a summary or specific content from these emails to Slack, it would generate another tool call, perhaps `slack.post_message`. `handle_tool_calls()` would then execute this by making an authenticated request to the Slack API, sending the specified message to the designated channel, again on behalf of the `user_id`. The `result` object returned by `handle_tool_calls()`  would typically contain the outcomes of these operations, which might then be used by the application to inform the user or to provide context for subsequent LLM interactions. This seamless execution of chained actions across different services is a key benefit of using a tool management layer like Composio.

## 4. Example Workflow: Automating Email Routing to Slack (from Dev.to Article)
The DEV Community article titled "I saved my team 20 hours by automating support emails with this AI tool ðŸ¤”"  provides a comprehensive example of building an AI-powered tool that integrates Gmail and Slack using Composio, CrewAI, and FastAPI. This example serves as a practical guide for implementing the authentication and tool execution flow required for the user's AI agent. The project described in the article focuses on automating the process of reading support emails, categorizing them based on keywords, and then routing them to appropriate Slack channels and email addresses. This workflow directly addresses the user's need to connect Gmail and Slack, perform actions (read Gmail, post to Slack), and handle the necessary authentication. The article details the tech stack, setup process, AI bot construction, backend API development with FastAPI, and frontend implementation, offering a complete picture of how such a system can be built.

### 4.1 Overview: AI agent processes emails, posts to Slack based on content
The core functionality of the AI tool described in the DEV Community article  revolves around an **AI agent that listens for new Gmail messages, processes their content, and intelligently routes them**. The workflow begins with the user configuring integrations for Gmail and Slack. The user also defines a set of keywords that the AI agent will use to filter and categorize incoming emails. For instance, emails containing words like "bugs," "errors," or "issues" might be routed to a specific Slack channel (e.g., `dev-channel`) and a particular email address. Similarly, emails with keywords like "collaboration" or "partnership" could be directed to a `growth-channel`. The AI agent continuously polls the Gmail inbox for new messages. When a new email arrives, the agent analyzes its subject and body content against the predefined keywords. If a match is found, the agent then forwards the email content, including any attachments, to the designated Slack channel and email address. This automated routing ensures that relevant information reaches the right teams or individuals promptly, improving response times and efficiency. The article highlights that this system was built to manage a high volume of emails related to tech support, feature requests, and collaborations, significantly reducing the manual effort involved .

The article  outlines a multi-step process for the AI agent's operation:
1.  **Connect Services**: The user connects their Gmail and Slack accounts to the application. This step is crucial for the agent to access the user's emails and post messages on their behalf.
2.  **Configure Keywords**: The user defines specific keywords and associates them with target email addresses and Slack channels. For example, the keyword "bill" might route emails to `hrishikesh@gmail.com` and the `hrishikesh-channel` on Slack.
3.  **Email Processing**: The AI tool, through its Gmail integration, actively monitors the user's inbox for new emails.
4.  **Intelligent Routing**: Upon receiving a new email, the AI agent (powered by CrewAI and an LLM like GPT-4o) analyzes the email's content. If the content matches any of the configured keywords, the agent then routes the email to the corresponding Slack channel and email ID. For example, an email with the subject "Urgent: Bug in production" would be analyzed, and if "bug" is a keyword for the `dev-team` channel, it would be posted there . The agent can also handle attachments by downloading them using `GMAIL_GET_ATTACHMENT` before forwarding.

This workflow demonstrates a practical application of an AI agent interacting with multiple external services (Gmail and Slack) based on user-defined rules and natural language processing. The use of Composio simplifies the integration with these external APIs, handling the underlying authentication and tool execution. The AI agent's ability to understand email content and make routing decisions showcases the power of combining LLMs with practical toolkits. The article also mentions sending an automatic reply to the sender of the email, acknowledging receipt, which is another common use case for an AI email assistant .

### 4.2 Composio CLI for Tool Setup: `composio add gmail`, `composio add slack`
The DEV Community article  details a setup process that heavily relies on the **Composio Command Line Interface (CLI)** to configure the necessary integrations for Gmail and Slack. This setup is encapsulated within a shell script (`setup.sh`) located in the `backend` directory of the example project. The script automates several steps to prepare the development environment and link the user's accounts. After creating and activating a Python virtual environment and installing dependencies from `requirements.txt`, the script proceeds to interact with the Composio CLI. The first crucial Composio command is **`composio login`**, which authenticates the user with their Composio account. This step typically involves opening a browser window for the user to log in or create an account, and then pasting an API key or authorization code back into the terminal. This API key (`COMPOSIO_API_KEY`) is essential for the Composio SDK to make authenticated requests on behalf of the user.

Once logged in, the script then uses **`composio add gmail`** and **`composio add slackbot`** (referred to as `composio add slackbot` in the script, though the toolkit name might be `slack`) to initiate the OAuth 2.0 authorization process for Gmail and Slack, respectively . When these commands are executed, Composio typically provides a redirect URL. The user needs to visit this URL in their web browser, which will take them to the Google or Slack OAuth consent screen. Here, the user will be asked to grant the application (Composio, acting on behalf of the user's AI agent) permission to access their Gmail account or Slack workspace. For Gmail, this might include permissions to read, send, and manage emails. For Slack, it might involve permissions to post messages to channels, read channel history, or other scopes depending on the actions the agent needs to perform. After the user grants consent, an authorization code is exchanged for an access token and refresh token, which Composio securely stores and manages. The article mentions that upon completing these integrations, the user can visit the Composio dashboard to monitor their connected applications . This CLI-driven setup abstracts away the complexities of manually registering OAuth applications with Google and Slack, obtaining client IDs and secrets, and handling the OAuth flow. The script also handles copying an `.env.example` file to `.env` and prompts the user to fill in necessary environment variables, including API keys for Composio and OpenAI .

The specific commands used in the `setup.sh` script are:
```bash
# Login to your account
echo "Login to your Composio account"
composio login

# Add Gmail tool
echo "Add Gmail tool"
composio add gmail

# Add Slackbot tool
echo "Add Slakbot tool"
composio add slackbot
```
Note the use of `slackbot` as the identifier for the Slack integration in this script. This is an important detail, as the toolkit name must be correct for the SDK and CLI to function properly. The article's setup script clearly indicates that `composio add gmail` and `composio add slackbot` are the commands used to link these services . This implies that the Composio platform is designed to handle the OAuth handshake and token management for these services once these commands are successfully run. The user is guided through the authentication process via their web browser, and upon completion, Composio manages the credentials, allowing the AI agent to make API calls to Gmail and Slack.

### 4.3 FastAPI Backend: Defining API endpoints for entity creation, triggers, and agent initialization
The backend of the example application described in the DEV Community article  is built using **FastAPI**, a modern Python web framework for building APIs. The `main.py` file in the backend directory contains the FastAPI application setup and defines several API endpoints crucial for the AI agent's operation. These endpoints facilitate user authentication (using Firebase, though the focus here is on Composio's role), entity management within Composio, trigger enabling for Gmail, and agent initialization. The article lists the following key endpoints:

1.  **`POST /new_entity`**: This endpoint is responsible for creating a new "entity" within Composio. An entity in Composio typically represents a user or a distinct set of tool configurations. The endpoint expects data including `username`, `appType` (e.g., 'gmail', 'slack'), and a `redirectUrl`. It is authenticated using a token (likely from Firebase), which is decoded to verify the user. This endpoint would interact with the Composio SDK or API to register the new entity and prepare for OAuth flows for the specified `appType`. The `redirectUrl` is important for the OAuth process, as it's where the user will be redirected after granting consent.

2.  **`POST /enable_trigger`**: This endpoint is used to enable a specific trigger, such as the `GMAIL_NEW_GMAIL_MESSAGE` trigger, for a given user (identified by `username`). The request body would contain `username`. When this endpoint is hit, it would communicate with Composio to activate the event listener for new Gmail messages for that user's connected Gmail account. This is essential for the AI agent to react to incoming emails in real-time or near real-time.

3.  **`POST /check_connection`**: This endpoint allows the frontend or other services to check if a specific entity (user + appType, e.g., 'user@example.com' and 'gmail') is successfully connected and authenticated within Composio. It would query Composio's system to verify the connection status, returning a boolean or a more detailed status object.

4.  **`POST /initialise_agent`**: This endpoint triggers the initialization of the AI agent for a specific user (identified by `username`). It would likely load the user's specific configurations (like keywords and routing rules) and prepare the CrewAI agent instance with the necessary tools and prompts. This might involve instantiating the `ComposioToolSet` with the user's `entity_id` (or `clientUniqueUserId` as seen in the callback function) and the required actions like `Action.GMAIL_SEND_EMAIL`, `Action.GMAIL_GET_ATTACHMENT`, `Action.GMAIL_REPLY_TO_THREAD`, and `Action.SLACKBOT_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL` .

The `main.py` file also includes setup for CORS (Cross-Origin Resource Sharing) using `CORSMiddleware` to allow requests from the frontend (e.g., running on `localhost:5173`). Pydantic models (`UserData`, `NewEntityData`, `EnableTriggerData`, `InitialiseAgentData`) are defined to validate the request bodies for these endpoints. The backend server is run using Uvicorn, typically on `0.0.0.0:8000` . These API endpoints form the bridge between the user interface (where users connect accounts and configure settings) and the Composio-powered AI agent logic. They handle the necessary setup and triggering mechanisms for the agent to perform its tasks of reading Gmail and posting to Slack. The article's example shows how a FastAPI backend can effectively manage user-specific configurations and orchestrate the interactions between Composio, the LLM (OpenAI), and the AI agent framework (CrewAI).

### 4.4 Event Listeners: Using `create_trigger_listener()` for new Gmail messages
A critical component of the AI agent described in the DEV Community article  is the event listener, which enables the system to react to new Gmail messages. This functionality is implemented using Composio's **`create_trigger_listener()` method**, part of the `ComposioToolSet` class. The `agent.py` script in the example project initializes this listener. The purpose of this listener is to monitor for specific events, such as the arrival of a new email in the user's Gmail inbox. When such an event occurs, Composio captures it and forwards the relevant data to a predefined callback function within the application. The article specifies setting up a listener for the **`GMAIL_NEW_GMAIL_MESSAGE` trigger** . This means that whenever a new email is detected by Composio for the authenticated Gmail account, the `callback_new_message` function (decorated with `@listener.callback`) is invoked.

The `callback_new_message` function receives an `event` object of type `TriggerEventData`. This object contains the `payload` of the new email, which includes details like the sender, subject, message body, and any metadata. The callback function then processes this email content. In the example, it extracts the sender's email and uses a `clientUniqueUserId` from `event.metadata.connection` to fetch user-specific configurations (like keywords and routing rules) from a Firebase database . Based on this information and the email content, the AI agent (a CrewAI agent in this case) is then tasked with deciding how to route the email. The `ComposioToolSet` is initialized within this callback with `entity_id=event.metadata.connection.clientUniqueUserId`, ensuring that any actions taken by the agent (like sending an email or posting to Slack) are performed in the context of the correct user's connected accounts. The listener is started by calling `listener.listen()`, which typically runs in a loop, waiting for events. This event-driven architecture is key to building responsive AI agents that can act upon real-time data from external services like Gmail, without the need for constant polling by the application itself, as Composio handles the underlying event detection and notification.

The relevant code snippet from `agent.py` for initializing the listener and defining the callback is:
```python
# Trigger instance
composio_toolset1 = ComposioToolSet(api_key=os.environ.get("COMPOSIO_API_KEY"))

# Initialize the event listener
listener = composio_toolset1.create_trigger_listener()

@listener.callback(filters={"trigger_name": "GMAIL_NEW_GMAIL_MESSAGE"})
def callback_new_message(event: TriggerEventData) -> None:
    print("Received new email")
    payload = event.payload
    sender_email = payload['sender']
    sender_email = sender_email.strip()
    # ... (user data fetching logic) ...
    
    # Tools for this specific event/user
    composio_toolset = ComposioToolSet(
        api_key=os.environ.get("COMPOSIO_API_KEY"),
        output_dir=Path.cwd() / "attachments",
        entity_id=event.metadata.connection.clientUniqueUserId)
    tools = composio_toolset.get_actions(actions=[Action.GMAIL_SEND_EMAIL,
                                                  Action.GMAIL_GET_ATTACHMENT,
                                                  Action.GMAIL_REPLY_TO_THREAD,
                                                  Action.SLACKBOT_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL])
    # ... (CrewAI agent and task definition) ...

print("Email trigger listener activated!")
listener.listen()
```
This setup shows how Composio facilitates event-driven interactions. The `filters={"trigger_name": "GMAIL_NEW_GMAIL_MESSAGE"}` ensures that the callback is only triggered for new Gmail message events. The `event.metadata.connection.clientUniqueUserId` is particularly important as it links the incoming event to a specific user's set of authenticated tools, allowing for multi-user support where each user has their own Gmail and Slack accounts connected via Composio.

### 4.5 AI Agent: Utilizing `ComposioToolSet` and `CrewAI` for task execution
The AI agent in the DEV Community article  is built using the **CrewAI framework**, with Composio providing the tools for interacting with Gmail and Slack. The `agent.py` script outlines the construction of this agent. After the `callback_new_message` function is triggered by a new Gmail event and fetches user-specific data, it proceeds to define and execute the AI agent. The core of this setup involves the `ComposioToolSet` and a CrewAI `Agent` instance. The `ComposioToolSet` is initialized with the `COMPOSIO_API_KEY` and, crucially, the `entity_id` (derived from `event.metadata.connection.clientUniqueUserId`). This `entity_id` ensures that the tools fetched and used by the agent are scoped to the specific user whose Gmail account received the new email. The `get_actions()` method of `ComposioToolSet` is then called to retrieve a list of available actions (tools) that the AI agent can use. The example explicitly lists `Action.GMAIL_SEND_EMAIL`, `Action.GMAIL_GET_ATTACHMENT`, `Action.GMAIL_REPLY_TO_THREAD`, and `Action.SLACKBOT_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL` . These actions represent the capabilities the AI agent has, such as sending emails, downloading attachments, replying to email threads, and posting messages to Slack channels.

Once the tools are defined, a CrewAI `Agent` named `email_assistant` is created. This agent is configured with a `role` (e.g., "Email Assistant"), a `goal` (e.g., "Process incoming emails, send auto-replies, and forward emails based on keywords"), and a `backstory`. It is also provided with the LLM instance (`lm`, which is `ChatOpenAI(model="gpt-4o")`), the `tools` fetched from Composio, and `allow_delegation=False`. A CrewAI `Task` named `process_new_email` is then defined. This task has a `description` (which is one of two prompts, `prompt1` or `prompt2`, selected based on whether the email is from the user themselves or an external sender), an `agent` (the `email_assistant`), and an `expected_output`. The prompts (`prompt1` and `prompt2`) contain detailed instructions for the LLM, including how to analyze the email content, check for keywords, download attachments if present, and format messages for Slack or email forwarding . Finally, a `Crew` is instantiated with the `email_assistant` agent and the `process_new_email` task, and the workflow is kicked off using `email_processing_crew.kickoff()`. The result of this execution is then returned or logged. This structure allows the LLM (GPT-4o) to decide which tools to use and how, based on the email content and the instructions in the prompt, effectively enabling the AI to read Gmail and post to Slack as required.

The agent definition in `agent.py` looks like this:
```python
# Agent
email_assistant = Agent(
    role="Email Assistant",
    goal="Process incoming emails, send auto-replies, and forward emails based on keywords",
    backstory="You're an AI assistant that handles incoming emails, sends automatic responses, and forwards emails to appropriate recipients based on content, including attachments.",
    verbose=True,
    llm=llm,
    tools=tools, # tools from ComposioToolSet
    allow_delegation=False,
)

task_description = prompt1 if user_email != sender_email else prompt2
process_new_email = Task(
    description=task_description,
    agent=email_assistant,
    expected_output="Summary of email processing...",
)

email_processing_crew = Crew(
    agents=[email_assistant],
    tasks=[process_new_email],
    verbose=1,
    process=Process.sequential,
)

result = email_processing_crew.kickoff()
```
This demonstrates how Composio's tools are seamlessly integrated into a CrewAI agent, allowing the LLM to leverage these external APIs to perform complex tasks based on natural language prompts and real-time data. The `entity_id` ensures that all actions are performed in the context of the correct user's authenticated sessions with Gmail and Slack.

## 5. Confirmation of Slack Toolkit Name
To correctly integrate and authorize Slack using the Composio SDK, it is essential to know the precise string identifier (the "toolkit name") that Composio uses for the Slack integration. This name is passed to methods like `composio.toolkits.authorize()` and `composio.tools.get()`. While the Gmail toolkit name was explicitly shown as `"gmail"` in the Composio Quickstart documentation , the Slack toolkit name was confirmed through an alternative source, providing the necessary detail to proceed with its implementation in the FastAPI backend. This confirmation ensures that the authorization requests and tool fetches for Slack are correctly targeted.

### 5.1 Evidence from `composio-crewai-sample` GitHub repository: `poetry run composio add slack`
The specific toolkit name for Slack integration with Composio was confirmed through an example found in the **`ComposioHQ/composio-crewai-sample` GitHub repository** . This repository provides setup instructions for a sample project that integrates Slack, Notion, and CrewAI using Composio. In the "Composio Integration" section of its setup steps, it lists commands to add integrations for Notion and Slack using the Composio CLI. The command for adding Slack is **`poetry run composio add slack`** . This CLI command directly corresponds to the programmatic authorization process. When using the Composio Python SDK, the `toolkit` parameter in methods like `composio.toolkits.authorize()` would use the string identifier `"slack"`. This evidence from a practical example solidifies that `"slack"` is the correct toolkit name to use when working with Slack integrations through Composio's Python SDK, ensuring that the OAuth flow and tool retrieval are correctly configured for the Slack service.

### 5.2 Implication: `toolkit="slack"` is the correct identifier for Slack integration
The evidence from the `composio-crewai-sample` GitHub repository, specifically the CLI command `poetry run composio add slack` , strongly implies that the string **`"slack"` is the official and correct toolkit identifier for Slack** within the Composio ecosystem. This means that when initializing an authorization request for Slack using the Python SDK, the code should be **`composio.toolkits.authorize(user_id=user_id, toolkit="slack")`**. Similarly, when fetching the Slack tool definitions, the `toolkits` parameter in `composio.tools.get()` should include `"SLACK"` (the documentation examples often show toolkit names in uppercase for the `get` method, but Composio SDKs usually handle case insensitivity or provide the correct format). Using the correct identifier is paramount; an incorrect name would lead to failures in finding the integration, initiating the OAuth flow, or retrieving the appropriate tool configurations. This confirmation allows for the accurate implementation of Slack authentication and tool usage in the web-based AI agent, mirroring the established pattern for Gmail but with the specific identifier for Slack.

## 6. Key Takeaways for FastAPI Backend Integration
Integrating Gmail and Slack authentication into a FastAPI AI agent using Composio offers a streamlined and secure approach. The process involves leveraging Composio's Python SDK to manage OAuth 2.0 flows, fetch authorized tool definitions, and execute actions based on the AI agent's decisions. This method significantly reduces the boilerplate code and complexity typically associated with direct OAuth implementations for multiple services. The following points summarize the crucial aspects for a successful integration.

### 6.1 Composio abstracts the complexities of individual OAuth 2.0 implementations for Gmail and Slack.
One of the most significant advantages of using Composio is its ability to **abstract away the intricate details of OAuth 2.0 implementations** for various services like Gmail and Slack . Instead of developers needing to write and maintain separate OAuth client setups, handle redirect URIs, manage state parameters, exchange authorization codes for tokens, and implement token refresh logic for each service, Composio provides a unified interface. The Composio SDK offers high-level methods like `toolkits.authorize()` and `provider.handle_tool_calls()` that encapsulate these complexities . This allows developers to focus on the core functionality of their AI agentâ€”such as natural language understanding and task orchestrationâ€”rather than the underlying authentication plumbing. By centralizing these OAuth management tasks, Composio ensures a more secure and maintainable integration, as best practices for OAuth are handled by the platform. This abstraction layer is crucial for rapidly developing AI agents that can interact with a wide range of external tools without requiring deep expertise in each service's specific authentication protocol.

### 6.2 The `user_id` parameter is crucial for associating tool authorizations with specific users.
The **`user_id` parameter plays a vital role** throughout the Composio integration process, ensuring that tool authorizations and subsequent actions are correctly scoped and attributed to individual users of the AI agent application . When initiating an authorization flow using `composio.toolkits.authorize(user_id, toolkit=...)`, the provided `user_id` is used by Composio to associate the obtained OAuth credentials (access tokens, refresh tokens) with that specific user. This is essential for multi-user applications where each user might connect their own Gmail and Slack accounts. Later, when fetching authorized tools with `composio.tools.get(user_id, toolkits=...)` or executing tool calls via `composio.provider.handle_tool_calls(user_id, ...)`, the same `user_id` is used to retrieve the correct set of credentials for that user. This ensures that the AI agent acts only on behalf of the authenticated user and accesses only the data and services that the user has explicitly authorized. **Proper management and consistent use of the `user_id` are therefore fundamental for security, privacy, and the correct functioning of the AI agent in a multi-user environment.**

### 6.3 The `tools` object obtained after authorization is essential for enabling the AI agent to interact with the connected services.
After successfully authorizing access to services like Gmail and Slack for a specific `user_id`, the **`tools` object obtained via `composio.tools.get(user_id, toolkits=["GMAIL", "SLACK"])` is a critical component** for enabling the AI agent to interact with these connected services . This `tools` object is not merely a list of tool names; it contains structured definitions of the available actions (e.g., "read_email," "post_message") in a format that is typically compatible with Large Language Models (LLMs) that support function or tool calling, such as OpenAI's GPT models. These definitions include the name of each tool, a natural language description of its function (which helps the LLM understand when to use it), and a schema defining its input parameters. By passing this `tools` object to the LLM (e.g., via the `tools` parameter in OpenAI's `chat.completions.create()` method), the AI model becomes "aware" of the external capabilities it can leverage. The LLM can then decide, based on the user's query, to generate a request to call one of these tools. This `tools` object, therefore, acts as the bridge between the user's authorization and the AI agent's ability to perform real-world actions through the integrated services.